{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating adversarial examples using FGSM (PFN coding interview 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my solution to the 2018 coding interview at Preferred Networks. (https://github.com/pfnet/intern-coding-tasks/tree/master/2018/ml)\n",
    "\n",
    "I did not apply for the internship, but found the problem interesting and wanted to solve it. The goal is to use the Fast Gradient Sign Method to generate adversarial examples of 32x32 pixel images of hand-written greek symbols.\n",
    "\n",
    "A key part of the challenge is that the use of external modules are forbidden, so we have to define all our functions ourselves. Since this is a notebook, and I want to explain each function while we define them, I will not create any classes to make the readability easier. For any real application, creating more compact classes is advisable.\n",
    "\n",
    "### Task description (from PFN interview)\n",
    "This task is about adversarial examples. You are given an image dataset of\n",
    "hand-written characters and a predictor (that is, a classifier) for the dataset.\n",
    "The objective is to modify the original input image by adding a small amount\n",
    "of noise so that the predictor will missclassify it. That is, we want to make an\n",
    "input image that will deceive the predictor.\n",
    "\n",
    "Back-story: Thanks to the advancement of machine learning and deep learning,\n",
    "prediction models are going to be used in important applications, such as\n",
    "autonomous driving and image authentication. One motivation for adversarial\n",
    "examples is considering the risk that malicious users may abuse such predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Helper functions without external modules\n",
    "Problem 1 is just to design helper functions for basic linear algebra methods, since we will use them in the later problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnitTests():\n",
    "    \n",
    "    def vec_dim_check(self,x,y):\n",
    "        if len(x) != len(y):\n",
    "            print(\"ERROR: Dimension of vectors does not match.\")\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def vec_elem_check(self,x):\n",
    "        if not all(isinstance(n,(int,float)) for n in x):\n",
    "            print(\"ERROR: Vectors can only contain ints or floats.\")\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def vec_mat_prod_check(self,A,x):\n",
    "        \n",
    "        A_dims = (len(A),len(A[0]))\n",
    "        x_dims = len(x)\n",
    "    \n",
    "        if x_dims != A_dims[1]:\n",
    "            print(\"ERROR: Dimension of matrix and vector does not match\")\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "UT = UnitTests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function calculates the sum of two vectors of equal dimensions. \"\"\"\n",
    "\n",
    "def vec_sum(x,y):\n",
    "    \n",
    "    if not UT.vec_elem_check(x):\n",
    "        return\n",
    "    if not UT.vec_dim_check(x,y):\n",
    "        return\n",
    "    \n",
    "    return list(map(lambda x,y: x+y, x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6]\n",
      "ERROR: Vectors can only contain ints or floats.\n",
      "None\n",
      "ERROR: Dimension of vectors does not match.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x1, y1 = [1,2,3], [1,2,3]\n",
    "x2, y2 = [\"a\",2,3], [1,2,3]\n",
    "x3, y3 = [1,2,3,4], [1,2,3]\n",
    "\n",
    "print(vec_sum(x1,y1))\n",
    "print(vec_sum(x2,y2))\n",
    "print(vec_sum(x3,y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function calculates the matrix-vector product.\"\"\"\n",
    "\n",
    "def vec_mat_prod(A, x):\n",
    "    \n",
    "    A_dims = (len(A),len(A[0]))\n",
    "    x_dims = len(x)\n",
    "    \n",
    "    if x_dims != A_dims[1]:\n",
    "        print(\"ERROR: Dimension of matrix and vector does not match\")\n",
    "    \n",
    "    y = [[] for n in range(A_dims[0])]\n",
    "    \n",
    "    for i in range(A_dims[0]):\n",
    "        y[i] = sum(A[i][j]*x[j] for j in range(x_dims))\n",
    "        \n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 32]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [[1,2,3],[4,5,6]]\n",
    "x = [1,2,3]\n",
    "vec_mat_prod(A,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function calculates the matrix transpose of input matrix A. Has to be a mutli-column matrix.\"\"\"\n",
    "def mat_transpose(A):\n",
    "        \n",
    "    row_dim = len(A)\n",
    "    col_dim = len(A[0])\n",
    "    \n",
    "    A_T = [[A[i][j] for i in range(row_dim)] for j in range(col_dim)]\n",
    "    return A_T\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6]]\n",
      "[[1, 4], [2, 5], [3, 6]]\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "print(mat_transpose(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function applies elementwise rectified linear unit on a vector. \"\"\"\n",
    "def ReLU(x):\n",
    "\n",
    "    if not UT.vec_elem_check(x):\n",
    "        return\n",
    "    \n",
    "    x = [max(0,x[i]) for i in range(len(x))]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLU([-1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function applies a normalized exponential transformation on a vector (i.e. softmax). \"\"\"\n",
    "def softMax(x):\n",
    "    \n",
    "    e = 2.7182818284\n",
    "    \n",
    "    exp_vector = [e**(x[n]) for n in range(len(x))]\n",
    "    exp_sum = sum(exp_vector)\n",
    "    \n",
    "    exp_vector = [exp_vector[n]/exp_sum for n in range(len(x))]\n",
    "    \n",
    "    return exp_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09003057317346094, 0.24472847105785542, 0.6652409557686837]\n",
      "Sum is normalized to 1.0\n"
     ]
    }
   ],
   "source": [
    "x = [-1,0,1]\n",
    "print(softMax(x))\n",
    "print(f\"Sum is normalized to {sum(softMax(x))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2a: Importing and converting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This is a simple function to load the pgm image files, which are 32x32 pixel. We unwrap them and store them\n",
    "    in a 32*32 = 1024 dim vector. Full path of files is given, because the use of external modules like os and sys \n",
    "    is not allowed. The first three lines of the pgm files is always\n",
    "    \n",
    "    P2\n",
    "    32 32\n",
    "    255\n",
    "    \n",
    "    and then the following lines are the pixel values in grayscale from 0 to 255. \"\"\"\n",
    "\n",
    "def read_pgm(n,key = \"normal\"):\n",
    "    path_dict = {\"normal\":\"/home/vegardbs/Machine Learning/intern-coding-tasks-master/2018/ml/pgm/\",\n",
    "                 \"adverse\":\"/home/vegardbs/Machine Learning/intern-coding-tasks-master/2018/ml/pgm_ad/\",\n",
    "                 \"baseline\":\"/home/vegardbs/Machine Learning/intern-coding-tasks-master/2018/ml/pgm_bl_ad/\"}\n",
    "    \n",
    "    path = path_dict[key]\n",
    "    file = open(path + str(n) + \".pgm\",\"r\")\n",
    "    data = file.read().split()\n",
    "    file.close()\n",
    "    \n",
    "    fig = data[4:]\n",
    "    fig_norm = [float(fig[n])/255 for n in range(len(fig))]\n",
    "    \n",
    "    return fig_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_matrix(A):\n",
    "    n_rows = len(A)\n",
    "    mat = []\n",
    "    \n",
    "    for n in range(n_rows):\n",
    "        mat.append(A[n].split())\n",
    "    \n",
    "    for i in range(len(mat)):\n",
    "        for j in range(len(mat[0])):\n",
    "            mat[i][j] = float(mat[i][j])\n",
    "        \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_vector(x):\n",
    "    for n in range(len(x)):\n",
    "        x[n] = float(x[n])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" In this task, we are given the parameters for a pre-trained network. The network arcitechture\n",
    "    is hidden layers of 256 neurons, and then 23 neurons in the output layer. Each of the 23 output neurons\n",
    "    corresponds to the 23 labels we have for the different types of greek symbols.\n",
    "    The parameters are stored in a txt file, where the first 256 lines is the weights of the first hidden layer,\n",
    "    then the next line is the biases of the first hidden layer, then 256 lines of the second hidden layer etc.\"\"\"\n",
    "\n",
    "def load_network_parameters(file_loc):\n",
    "\n",
    "    file = open(file_loc,\"r\")\n",
    "    data = file.readlines()\n",
    "    file.close()\n",
    "    \n",
    "    H = 256\n",
    "    C = 23\n",
    "\n",
    "    W1 = data[:H]\n",
    "    W1 = convert_to_matrix(W1)\n",
    "\n",
    "    b1 = data[H].split()\n",
    "    b1 = convert_to_vector(b1)\n",
    "\n",
    "    W2 = data[H+1:2*H+1]\n",
    "    W2 = convert_to_matrix(W2)\n",
    "\n",
    "    b2 = data[2*H+1].split()\n",
    "    b1 = convert_to_vector(b2)\n",
    "\n",
    "    W3 = data[2*H+2:2*H + 2 + C]\n",
    "    W3 = convert_to_matrix(W3)\n",
    "\n",
    "    b3 = data[-1].split()\n",
    "    b3 = convert_to_vector(b3)\n",
    "    \n",
    "    return W1,b1,W2,b2,W3,b3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = \"/home/vegardbs/Machine Learning/intern-coding-tasks-master/2018/ml/param.txt\"\n",
    "W1,b1,W2,b2,W3,b3 = load_network_parameters(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Here we import the labels and store them in a vector. \"\"\"\n",
    "\n",
    "file = open(\"/home/vegardbs/Machine Learning/intern-coding-tasks-master/2018/ml/labels.txt\",\"r\")\n",
    "labels = file.read().split()\n",
    "file.close()\n",
    "labels = convert_to_vector(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2b: Using the predictor model to classify greek symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The predict function takes the image vectors as input, and runs them through the neural network with \n",
    "    pretrained weights. The output layer is a softmax layer where the index of the largest element is the \n",
    "    networks prediction of the label (which greek character the image represents).\"\"\"\n",
    "\n",
    "def predict(x):\n",
    "    a1 = vec_sum(vec_mat_prod(W1,x),b1)\n",
    "    h1 = ReLU(a1)\n",
    "    a2 = vec_sum(vec_mat_prod(W2,h1),b2)\n",
    "    h2 = ReLU(a2)\n",
    "    y  = vec_sum(vec_mat_prod(W3,h2),b3)\n",
    "    f = softMax(y)\n",
    "    return f, float(f.index(max(f))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Here we run through all the images, and compare the networks prediction with the true labels.\"\"\"\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for n in range(1,155):\n",
    "    x = read_pmg(n)\n",
    "    _, pred = predict(x)\n",
    "    true = labels[n-1]\n",
    "    \n",
    "    if true == pred:\n",
    "        correct += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 85.1%\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct/len(labels)\n",
    "print(f\"The accuracy of the model is {100*accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3a: Implementing Fast Gradient Sign Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward(x,y):\n",
    "    \n",
    "    if not UT.vec_dim_check(x,y):\n",
    "        return\n",
    "    if not UT.vec_elem_check(x) and UT.vec_elem_check(y):\n",
    "        return\n",
    "\n",
    "    vec = []\n",
    "    for i in range(len(x)):\n",
    "        if y[i] > 0:\n",
    "            vec.append(x[i])\n",
    "        else:\n",
    "            vec.append(0)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 3, 4]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Backward([1,2,3,4],[-1,0,1/1e10,1e10])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(x,e_0):\n",
    "    x = [+1.0*e_0 if elem > 0 else -1.0*e_0 for elem in x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.0, -2.0, 2.0]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign([-1,0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "a.index(max(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_vec(seed,length):\n",
    "    X = seed\n",
    "    a = 1664525\n",
    "    b = 1013904223\n",
    "    m = 2**32\n",
    "    vec = []\n",
    "    \n",
    "    for n in range(length):\n",
    "        X = (a*X+b)%m\n",
    "        vec.append(X/m-0.5)\n",
    "        \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.26276936987414956, 0.050678204046562314, 0.3736585769802332]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_vec(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_adverse(x,e_0, label, baseline = False, seed = 1234):\n",
    "    \n",
    "    a1 = vec_sum(vec_mat_prod(W1,x),b1)\n",
    "    h1 = ReLU(a1)\n",
    "    a2 = vec_sum(vec_mat_prod(W2,h1),b2)\n",
    "    h2 = ReLU(a2)\n",
    "    y  = vec_sum(vec_mat_prod(W3,h2),b3)\n",
    "    f = softMax(y)\n",
    "    \n",
    "    dt = [0.0]*len(f)\n",
    "    dt[int(label)-1] = -1.0    \n",
    "    \n",
    "    D_y_L = vec_sum(dt,f)\n",
    "    D_h2_L = vec_mat_prod(mat_transpose(W3),D_y_L)\n",
    "    D_a2_L = Backward(D_h2_L,a2)\n",
    "    D_h1_L = vec_mat_prod(mat_transpose(W2), D_a2_L)\n",
    "    D_a1_L = Backward(D_h1_L,a1)\n",
    "    D_x_L = vec_mat_prod(mat_transpose(W1), D_a1_L)\n",
    "    \n",
    "    if baseline == True:\n",
    "        rand_vec = random_vec(seed,length=len(x))\n",
    "        bl_epsilon = sign(rand_vec,e_0)\n",
    "        x_bl = vec_sum(x,bl_epsilon)\n",
    "        x_bl = [int((elem + e_0)*(255/(1+2*e_0))) for elem in x_bl]\n",
    "        return x_bl\n",
    "    else:\n",
    "        epsilon = sign(D_x_L,e_0)\n",
    "        x_ad = vec_sum(x,epsilon)\n",
    "        x_ad = [int((elem + e_0)*(255/(1+2*e_0))) for elem in x_ad]\n",
    "        return x_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ad_fig(x_ad,n,baseline = False):\n",
    "    if baseline == False:\n",
    "        path = \"/home/vegardbs/Machine Learning/intern-coding-tasks-master/2018/ml/pgm_ad/\"\n",
    "    else:\n",
    "        path = \"/home/vegardbs/Machine Learning/intern-coding-tasks-master/2018/ml/pgm_bl_ad/\"\n",
    "\n",
    "    file = open(path + str(n) + \".pgm\",\"w+\")    \n",
    "    file.write(\"P2\\n\")\n",
    "    file.write(\"32 32\\n\")\n",
    "    file.write(\"255\\n\")\n",
    "    \n",
    "    k = 0\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            file.write(str(x_ad[k]) + \" \")\n",
    "            k += 1\n",
    "        file.write(\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Here we create adversal figures \"\"\"\n",
    "\n",
    "for n in range(1,len(labels)+1):\n",
    "    e_0 = 0.1\n",
    "\n",
    "    x = read_pgm(n)\n",
    "    label = labels[n-1]\n",
    "    x_ad = predict_adverse(x,e_0,label,baseline=True)\n",
    "    save_ad_fig(x_ad,n,baseline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Here we try to predict the adversal images, and compare the networks prediction with the true labels.\"\"\"\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for n in range(1,len(labels)+1):\n",
    "    x = read_pgm(n,key = \"adverse\")\n",
    "    _, pred = predict(x)\n",
    "    true = labels[n-1]\n",
    "    if true == pred:\n",
    "        correct += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.6%\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct/len(labels)\n",
    "print(f\"The accuracy of the model is {100*accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Here we run through the the adversal images created by adding random noise (the baseline), \n",
    "    and compare the networks prediction with the true labels.\"\"\"\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for n in range(1,len(labels)+1):\n",
    "    x = read_pgm(n,key = \"baseline\")\n",
    "    _, pred = predict(x)\n",
    "    true = labels[n-1]\n",
    "    \n",
    "    if true == pred:\n",
    "        correct += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 81.8%\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct/len(labels)\n",
    "print(f\"The accuracy of the model is {100*accuracy:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
